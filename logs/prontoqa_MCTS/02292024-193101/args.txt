['examples/prontoqa/rap_inference.py', '--model_dir', 'meta-llama/Llama-2-13b-chat-hf', '--depth_limit', '6', '--w_exp', '2']
