['examples/cot_gsm8k/inference.py', '--base_lm', 'hf', '--hf_path', 'meta-llama/Llama-2-13b-chat-hf', '--log_dir', 'logs/gsm8k_cot_v1.1', '--hf_quantized', 'nf4']
